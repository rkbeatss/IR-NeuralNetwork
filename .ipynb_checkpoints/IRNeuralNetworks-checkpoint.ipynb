{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1> Paraphrase Detection with Neural Networks - Natural Language Understanding </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSI4106 Artificial Intelligence Project <br/>\n",
    "Prepared by Abha Sharma & Rupsi Kaushik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Background </h2>\n",
    "\n",
    "With the growing trends of virtual assistants and chatbots, Natural Language Processing (NLP) is a topic that is becoming increasingly popular in the recent years. From Google AI's Transformer-based models that consider a word's double-sided context to IBM's training data generator, today we have cutting edge approaches to solving NLP tasks.  However, even with these latest breakthroughs, NLP still faces many challenges, namely the problem of accurately deciphering what humans mean when they express something, regardless of how they express it. This problem falls under Natural Language Understanding (NLU), a subtopic of NLP that aims to increase the proficiency of intelligent systems in exhibiting real knowledge of natural language. Within this field, the task of paraphrase detection - determining whether a pair of sentences convey identical meaning - is considered to be an important one. Through the improvement of paraphrase detection, other NLP tasks that are integral to the efficiency of existing intelligent systems, such as question answering, information retrieval, and text summarization, can also be improved. For this reason, in this report, we propose to enhance the capability of neural networks in the context of paraphrase detection through the use of traditional Information Retrieval (IR) techniques as input features. \n",
    "\n",
    "\n",
    "*add and edit as you want*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Objectives </h2>\n",
    "\n",
    "The main objective of this report is to evaluate the performance of a neural network model given different IR features. Additionally, it will take a look at how the number of features and hidden layers improve the overall performance of the model. These results will be compared among two different training sets that have been annotated for paraphrase detection. Below is the proposed architecture for our particular neural network: \n",
    "\n",
    "*adding the diagram & add and edit as you want* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Datasets </h2>\n",
    "\n",
    "We will be working with the Quora Question Pairs and Microsoft Research Paraphrase Corpus datasets for this project. You can find them in this folder labelled as 'msr_train.csv' and 'questions_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure to import all these modules\n",
    "import pandas as pd\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "from pyemd import emd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.wsd import lesk\n",
    "from nltk import ngrams\n",
    "from difflib import SequenceMatcher\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at the Quora Question Pairs dataset\n",
    "quora_data = pd.read_csv(\"questions_train.csv\", error_bad_lines=False)\n",
    "quora_data.Sentence_1 = quora_data.Sentence_1.astype(str)\n",
    "quora_data.Sentence_2 = quora_data.Sentence_2.astype(str)\n",
    "quora_data = quora_data[:4000]\n",
    "quora_data.is_Paraphrase = quora_data.is_Paraphrase.astype(int)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a look at the Microsoft Research Paraphrase dataset \n",
    "mrp_data = pd.read_csv(\"msr_train.csv\")\n",
    "mrp_data.Sentence_1 = mrp_data.Sentence_1.astype(str)\n",
    "mrp_data.Sentence_2 = mrp_data.Sentence_2.astype(str)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing & Transformation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence):\n",
    "    stop_words = stopwords.words('english')\n",
    "    processed_sentence = [word for word in sentence if not word in stop_words]\n",
    "    return processed_sentence     \n",
    "def tokenize(sentence):\n",
    "    tokenized_sentence = sentence.lower().split()\n",
    "    return tokenized_sentence\n",
    "def lemmatize(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "    return lemmatized_sentence\n",
    "def add_synonym(word):\n",
    "    synonym_list = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for name in syn.lemma_names():\n",
    "             synonym_list.append(name.split(\".\")[0].replace('_',' '))\n",
    "    return list(set(synonym_list))\n",
    "def add_antonym(word):\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            if(lemma.antonyms()):\n",
    "                return lemma.antonyms()[0].name()\n",
    "            else:\n",
    "                return None           \n",
    "def add_hypernym(word):\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for hypernym in syn.hypernyms():\n",
    "            return hypernym.name().split('.')[0]\n",
    "def tokenize_negation(sentence):\n",
    "    negation_adverbs = [\"no\", \"without\",\"not\", \"n't\", \"never\", \"neith\", \"nor\"]\n",
    "    tokens_with_negation = []\n",
    "    tokenized_sentence = tokenize(sentence)\n",
    "    i = 0\n",
    "    while i < (len(tokenized_sentence)):\n",
    "        if (i != len(tokenized_sentence)-1) and (tokenized_sentence[i] in negation_adverbs):\n",
    "            negation_token = add_antonym(tokenized_sentence[i+1])\n",
    "            if(negation_token):\n",
    "                tokens_with_negation.append(negation_token)\n",
    "                i += 2 \n",
    "            else:\n",
    "                tokens_with_negation.append(tokenized_sentence[i])\n",
    "                i +=1\n",
    "        else:\n",
    "            tokens_with_negation.append(tokenized_sentence[i])\n",
    "            i += 1\n",
    "    return tokens_with_negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Syntactic Similarity</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Edit Distance</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain Edit Distance* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(row):\n",
    "    sentence_one_tokenize = tokenize(row['Sentence_1'])\n",
    "    sentence_two_tokenize = tokenize(row['Sentence_2'])\n",
    "    return nltk.edit_distance(sentence_one_tokenize, sentence_two_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Applying Edit Distance to Quora sentence pairs \n",
    "quora_data['Edit_distance'] = quora_data.apply(edit_distance, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Edit Distance to MRP Corpus sentence pairs \n",
    "mrp_data['Edit_distance'] = mrp_data.apply(edit_distance, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Jaccard Similarity Coefficient</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain Jaccard - smoothing with 1* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim_coefficient(row):\n",
    "    sentence_one_tokenize = tokenize(row['Sentence_1'])\n",
    "    sentence_two_tokenize = tokenize(row['Sentence_2'])\n",
    "    intersection = 0\n",
    "    for word_in_one in sentence_one_tokenize:\n",
    "        for word_in_two in sentence_two_tokenize:\n",
    "            if word_in_one == word_in_two:\n",
    "                intersection += 1\n",
    "    union = (len(sentence_one_tokenize) + len(sentence_two_tokenize) - intersection)\n",
    "    smoothed_intersection = intersection + 1\n",
    "    smoothed_union = union + (len(sentence_one_tokenize) + len(sentence_two_tokenize))\n",
    "    return smoothed_intersection/smoothed_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Jaccard Similarity Coefficient to Quora sentence pairs \n",
    "quora_data['Jaccard_similarity'] = quora_data.apply(jaccard_sim_coefficient, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Jaccard Similarity Coefficient to MRP Corpus sentence pairs \n",
    "mrp_data['Jaccard_similarity'] = mrp_data.apply(jaccard_sim_coefficient, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Sequence Matcher</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain Sequence Matcher*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_matcher(row):\n",
    "    return SequenceMatcher(None, row['Sentence_1'], row['Sentence_2']).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Sequence Matcher to Quora sentence pairs \n",
    "quora_data['Sequence_matcher'] = quora_data.apply(sequence_matcher, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Sequence Matcher to MRP Corpus sentence pairs \n",
    "mrp_data['Sequence_matcher'] = mrp_data.apply(sequence_matcher, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>N-gram measure</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain N-gram measure, n=3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_measure(row):\n",
    "    n = 3\n",
    "    common_count = 1\n",
    "    grams_sentence_one = ngrams(row['Sentence_1'].split(), n)\n",
    "    grams_sentence_two = ngrams(row['Sentence_2'].split(), n)\n",
    "    grams_sentence_one_total = sum(1 for x in grams_sentence_one)\n",
    "    grams_sentence_two_total = sum(1 for x in grams_sentence_two)\n",
    "    for gram_in_one in grams_sentence_one:\n",
    "        if gram_in_one in grams_sentence_two:\n",
    "            common_count += 1\n",
    "    return common_count / (grams_sentence_one_total + grams_sentence_two_total - common_count + grams_sentence_one_total + grams_sentence_two_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying N-gram Measure to Quora sentence pairs \n",
    "quora_data['N-gram_measure'] = quora_data.apply(ngram_measure, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying N-gram Measure to MRP Corpus sentence pairs \n",
    "mrp_data['N-gram_measure'] = mrp_data.apply(ngram_measure, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Pairwise Cosine Similarity </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(row):\n",
    "    sentence_one_tokenize = tokenize_negation(row['Sentence_1'])\n",
    "    sentence_two_tokenize = tokenize_negation(row['Sentence_2'])\n",
    "    filtered_sentence_one = remove_stop_words(sentence_one_tokenize)\n",
    "    filtered_sentence_two = remove_stop_words(sentence_two_tokenize)\n",
    "    #lemmatize to get the root words \n",
    "    lemmatize_sentence_one = lemmatize(filtered_sentence_one)\n",
    "    lemmatize_sentence_two = lemmatize(filtered_sentence_two)\n",
    "    return calculate_cosine_similarity(lemmatize_sentence_one, lemmatize_sentence_two)\n",
    "def calculate_cosine_similarity(sentence_one, sentence_two):\n",
    "    tfidf = TfidfVectorizer(preprocessor=' '.join)\n",
    "    tfidf_matrix = tfidf.fit_transform([sentence_one, sentence_two])\n",
    "    similarity = cosine_similarity(tfidf_matrix)[0,1]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Cosine Similaritye to Quora sentence pairs \n",
    "quora_data['Cosine_Similarity'] = quora_data.apply(get_cosine_similarity, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Cosine Similarity to MRP Corpus sentence pairs \n",
    "mrp_data['Cosine_Similarity'] = mrp_data.apply(get_cosine_similarity, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Semantic Similarity</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Word Mover's Distance </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain WMD here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_movers_distance(row):\n",
    "    sentence_one_tokenize = tokenize(row['Sentence_1'])\n",
    "    sentence_two_tokenize = tokenize(row['Sentence_2'])\n",
    "    filtered_sentence_one = remove_stop_words(sentence_one_tokenize)\n",
    "    filtered_sentence_two = remove_stop_words(sentence_two_tokenize)\n",
    "    distance = word_vectors.wmdistance(filtered_sentence_one, filtered_sentence_two)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Word Mover's Distance to Quora sentence pairs \n",
    "quora_data['WMD_distance'] = quora_data.apply(word_movers_distance, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Word Mover's Distance to MRP Corpus sentence pairs \n",
    "mrp_data['WMD_distance'] = mrp_data.apply(word_movers_distance, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Named Entity Recognition Similarity</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain NER with jaccard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_measure(row):\n",
    "    ner_sentence_one=[]\n",
    "    ner_sentence_two=[]\n",
    "    count_common_ner = 0\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(row['Sentence_1']))):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            ner_sentence_one.append(chunk)\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(row['Sentence_2']))):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            ner_sentence_two.append(chunk)\n",
    "    for item in ner_sentence_one:\n",
    "        if item in ner_sentence_two:\n",
    "            count_common_ner += 1\n",
    "    smoothed_intersection = count_common_ner + 1\n",
    "    union = len(ner_sentence_one) + len(ner_sentence_two) - count_common_ner\n",
    "    smoothed_union = union + len(ner_sentence_one) + len(ner_sentence_two)\n",
    "    # smoothed union set as 1 if both sentences have no NER\n",
    "    if smoothed_union == 0:\n",
    "        smoothed_union = 1\n",
    "    return smoothed_intersection / smoothed_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying NER Measure to Quora sentence pairs \n",
    "quora_data['NER_similarity'] = quora_data.apply(ner_measure, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying NER Measure to MRP Corpus sentence pairs \n",
    "mrp_data['NER_similarity'] = mrp_data.apply(ner_measure, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Word Sense Disambiguation</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain WSD using Lesk algorithm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsd(row):\n",
    "    sentence_one_senses = []\n",
    "    sentence_two_senses = []\n",
    "    common_senses = 0\n",
    "    sentence_one_tokenize = tokenize(row['Sentence_1'])\n",
    "    sentence_two_tokenize = tokenize(row['Sentence_2'])\n",
    "    for word in sentence_one_tokenize:\n",
    "        sentence_one_senses.append(lesk(row['Sentence_1'], word))\n",
    "    for word in sentence_two_tokenize:\n",
    "        sentence_two_senses.append(lesk(['Sentenece_2'], word))\n",
    "    sentence_one_senses = (set(sentence_one_senses))\n",
    "    sentence_two_senses = (set(sentence_two_senses))\n",
    "\n",
    "    for sense in sentence_one_senses:\n",
    "        if sense in sentence_two_senses:\n",
    "            common_senses += 1\n",
    "    return common_senses / (len(sentence_one_senses) + len(sentence_two_senses) - common_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying WSD Measure to Quora sentence pairs \n",
    "quora_data['WSD'] = quora_data.apply(wsd, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying WSD Measure to MRP Corpus sentence pairs \n",
    "mrp_data['WSD'] = mrp_data.apply(wsd, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Synonym Extended Cosine Similarity </h4>\n",
    "Here, we will use WordNet's capabilities to extend our dictionary. We will then call our existing calculate_cosine_similarity method to get the similarity of the extended documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_sentence_wordnet(row):\n",
    "    sentence_one_tokenize = tokenize_negation(row['Sentence_1'])\n",
    "    sentence_two_tokenize = tokenize_negation(row['Sentence_2'])\n",
    "    filtered_sentence_one = remove_stop_words(sentence_one_tokenize)\n",
    "    filtered_sentence_two = remove_stop_words(sentence_two_tokenize)\n",
    "    #lemmatize to get the root words \n",
    "    lemmatize_sentence_one = lemmatize(filtered_sentence_one)\n",
    "    lemmatize_sentence_two = lemmatize(filtered_sentence_two)\n",
    "    # get extended synonym list    \n",
    "    extended_dictionary_one = []\n",
    "    extended_dictionary_two = []\n",
    "    for one, two in zip(lemmatize_sentence_one, lemmatize_sentence_two):\n",
    "        synonym_one = add_synonym(one)\n",
    "        synonym_two = add_synonym(two)\n",
    "        hypernym_one = add_hypernym(one)\n",
    "        hypernym_two = add_hypernym(two)\n",
    "        if(synonym_one):\n",
    "            extended_dictionary_one += synonym_one\n",
    "        if(hypernym_one):\n",
    "            extended_dictionary_one += hypernym_one\n",
    "        if(synonym_two):\n",
    "            extended_dictionary_two += synonym_two\n",
    "        if(hypernym_two):\n",
    "            extended_dictionary_two += hypernym_two\n",
    "    lemmatize_sentence_one += extended_dictionary_one\n",
    "    lemmatize_sentence_two += extended_dictionary_two\n",
    "    \n",
    "    #calculate similarity based on the extended list \n",
    "    similarity = calculate_cosine_similarity(lemmatize_sentence_one, lemmatize_sentence_two)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Synonym_Cosine to Quora sentence pairs \n",
    "quora_data['Synonym_Hypernym_Cosine'] = quora_data.apply(extend_sentence_wordnet, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mrp_data['Synonym_Hypernym_Cosine'] = mrp_data.apply(extend_sentence_wordnet, axis = 1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Hypernym Extended Similarity </h4>\n",
    "Checking if words are near by in hypernym hierarchy  <br/>\n",
    "Wordnet hierarchy augmented with probabilities  <br />\n",
    "Then calculate shortest path based on similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train Set & Test Set </h2>\n",
    "\n",
    "For training with less bias, we want to maintain a reasonably equal class distribution. We want to make sure that we have a balanced class of non-paraphrase, as well as paraphrase pairs of sentences. If this is not possible, as with most real-life scenarios, we need to think of a way to adjust our metric for evaluation in order to accomodate for this imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mrp Data:\\n{}\".format(mrp_data['is_Paraphrase'].value_counts()))\n",
    "print(\"Quora Data:\\n{}\".format(quora_data['is_Paraphrase'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Measures </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, actual_tags):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for prediction, actual in zip(model, actual_tags):\n",
    "        total += 1\n",
    "        if prediction == actual:\n",
    "            correct += 1 \n",
    "    accuracy = correct / total \n",
    "    return '{0:.1%}'.format(accuracy)\n",
    "def build_confusion_matrix(actual_tags, model, classOfInterest):\n",
    "    confusion_matrix = {}\n",
    "    truePositives = len([p for p, a in zip(model, actual_tags) if p == a and p == classOfInterest])\n",
    "    trueNegatives = len([p for p, a in zip(model, actual_tags) if p == a and p != classOfInterest])\n",
    "    falsePositives = len([p for p, a in zip(model, actual_tags) if p != a and p == classOfInterest])\n",
    "    falseNegatives = len([p for p, a in zip(model, actual_tags) if p != a and p != classOfInterest])\n",
    "    confusion_matrix[\"tp\"] = truePositives\n",
    "    confusion_matrix[\"tn\"] = trueNegatives\n",
    "    confusion_matrix[\"fp\"] = falsePositives \n",
    "    confusion_matrix[\"fn\"] = falseNegatives\n",
    "    return confusion_matrix\n",
    "def calculate_recall(model, actual_tags, classOfInterest):\n",
    "    matrix = build_confusion_matrix(model, actual_tags, classOfInterest)\n",
    "    recall = matrix[\"tp\"] / ( matrix[\"tp\"] + matrix [\"fn\"])\n",
    "    return '{0:.1%}'.format(recall)\n",
    "def calculate_precision(model, actual_tags, classOfInterest):\n",
    "    matrix = build_confusion_matrix(model, actual_tags, classOfInterest)\n",
    "    precision = matrix[\"tp\"]/ (matrix[\"tp\"] + matrix[\"fp\"])\n",
    "    return '{0:.1%}'.format(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Model </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Baseline Model </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, instead of randomly picking a threshold for the baseline method, we are going to 'learn' a threshold that yields best results for us in terms of accuracy, recall, and precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_threshold(row, **kwargs):\n",
    "    if(row['Cosine_Similarity'] > kwargs['threshold']):\n",
    "        classification = 1\n",
    "    else:\n",
    "        classification = 0\n",
    "    return classification\n",
    "\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "quora_data_thresholds = {}\n",
    "mrp_data_thresholds = {}\n",
    "accuracies = {}\n",
    "recalls = {}\n",
    "precisions = {}\n",
    "for threshold in thresholds:\n",
    "    quora_data_thresholds[threshold] = quora_data.apply(learn_threshold, threshold = threshold, axis = 1)\n",
    "    accuracies[threshold] = calculate_accuracy(quora_data_thresholds[threshold], quora_data['is_Paraphrase'])\n",
    "    recalls[threshold] = calculate_recall(quora_data_thresholds[threshold], quora_data['is_Paraphrase'], 1)\n",
    "    precisions[threshold] = calculate_precision(quora_data_thresholds[threshold], quora_data['is_Paraphrase'], 1)\n",
    "print(\"Quora Accuracy: {}, \\n Quora Recall: {},\\nQuora Precision: {}\" .format(accuracies, recalls, precisions))\n",
    "\n",
    "for threshold in thresholds:\n",
    "    mrp_data_thresholds[threshold] = mrp_data.apply(learn_threshold, threshold = threshold, axis = 1)\n",
    "    accuracies[threshold] = calculate_accuracy(mrp_data_thresholds[threshold], mrp_data['is_Paraphrase'])\n",
    "    recalls[threshold] = calculate_recall(mrp_data_thresholds[threshold], mrp_data['is_Paraphrase'],1)\n",
    "    precisions[threshold] = calculate_precision(mrp_data_thresholds[threshold], mrp_data['is_Paraphrase'], 1)\n",
    "print(\"MRP Accuracy: {}, \\nMRP Recall: {},\\nMRP Precision: {}\" .format(accuracies, recalls, precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_cosine_classification(row):\n",
    "    if (row['Cosine_Similarity'] > 0.5):\n",
    "        classification = 1\n",
    "    else:\n",
    "        classification = 0\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_baseline = {}\n",
    "quora_baseline['Cosine_Classification'] = quora_data.apply(apply_cosine_classification, axis=1)\n",
    "print(quora_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrp_baseline = {}\n",
    "mrp_baseline['Cosine_Classification'] = mrp_data.apply(apply_cosine_classification, axis=1)\n",
    "print(mrp_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Post Process </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_quora = quora_data.loc[quora_data['WMD_distance'] != np.nan, 'WMD_distance'].max()\n",
    "quora_data['WMD_distance'].replace(np.nan, max_quora, inplace=True)\n",
    "x = quora_data[['WMD_distance']].values.astype(float)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "quora_data['WMD_distance'] = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "max_microsoft = mrp_data.loc[mrp_data['WMD_distance'] != np.nan, 'WMD_distance'].max()\n",
    "mrp_data['WMD_distance'].replace(np.nan, max_microsoft, inplace=True)\n",
    "y = mrp_data[['WMD_distance']].values.astype(float)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "y_scaled = min_max_scaler.fit_transform(y)\n",
    "mrp_data['WMD_distance'] = pd.DataFrame(y_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Multi-layer Perceptron </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(df):\n",
    "    properties = list(df.columns.values)\n",
    "    properties.remove('is_Paraphrase')\n",
    "    properties.remove('Sentence_1')\n",
    "    properties.remove('Sentence_2')\n",
    "    # properties.remove('NER_similarity')\n",
    "    X = df[properties]\n",
    "    y = df['is_Paraphrase']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(9,)),\n",
    "    keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(7, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=15, batch_size=1)\n",
    "\n",
    "    test_loss, test_acc, test_pre, test_recall = model.evaluate(X_test, y_test)\n",
    "    print('Test accuracy:{}, test recall: {}, test precision: {}'.format(test_acc, test_recall, test_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multi-Layer Perceptron Results for quora_data\")\n",
    "multilayer_perceptron(quora_data)\n",
    "print(\"\\n*********************************************************************************\\n\")\n",
    "print(\"Multi-Layer Perceptron Results for mrp_data\")\n",
    "multilayer_perceptron(mrp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Results & Evaluation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_baseline_accuracy = calculate_accuracy(quora_baseline['Cosine_Classification'], quora_data['is_Paraphrase'])\n",
    "quora_baseline_recall = calculate_recall(quora_baseline['Cosine_Classification'], quora_data['is_Paraphrase'], 1)\n",
    "quora_baseline_precision = calculate_precision(quora_baseline['Cosine_Classification'], quora_data['is_Paraphrase'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy = calculate_accuracy(mrp_baseline['Cosine_Classification'], mrp_data['is_Paraphrase'])\n",
    "baseline_recall = calculate_recall(mrp_baseline['Cosine_Classification'], mrp_data['is_Paraphrase'], 1)\n",
    "baseline_precision = calculate_precision(mrp_baseline['Cosine_Classification'], mrp_data['is_Paraphrase'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline_evaluation_summary = {\"Model\": ['Baseline'],\n",
    "                   \"Accuracy\":[(baseline_accuracy)], \n",
    "                   \"Recall\":[baseline_recall], \n",
    "                   \"Precision\":[baseline_precision]}\n",
    "results_df = pd.DataFrame(baseline_evaluation_summary)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_baseline_evaluation_summary = {\"Model\": ['Quora'],\n",
    "                   \"Accuracy\":[(quora_baseline_accuracy)], \n",
    "                   \"Recall\":[quora_baseline_recall], \n",
    "                   \"Precision\":[quora_baseline_precision]}\n",
    "quora_results_df = pd.DataFrame(quora_baseline_evaluation_summary)\n",
    "print(quora_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> References </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
