{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2> Paraphrase Detection with Neural Networks - Natural Language Understanding </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSI4106 Artificial Intelligence Project <br/>\n",
    "Prepared by Abha Sharma & Rupsi Kaushik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Background </h3>\n",
    "\n",
    "With the growing trends of virtual assistants and chatbots, Natural Language Processing (NLP) is a topic that is becoming increasingly popular in the recent years. From Google AI's Transformer-based models that consider a word's double-sided context to IBM's training data generator, today we have cutting edge approaches to solving NLP tasks.  However, even with these latest breakthroughs, NLP still faces many challenges, namely the problem of accurately deciphering what humans mean when they express something, regardless of how they express it. This problem falls under Natural Language Understanding (NLU), a subtopic of NLP that aims to increase the proficiency of intelligent systems in exhibiting real knowledge of natural language. Within this field, the task of paraphrase detection - determining whether a pair of sentences convey identical meaning - is considered to be an important one. Through the improvement of paraphrase detection, other NLP tasks that are integral to the efficiency of existing intelligent systems, such as question answering, information retrieval, and text summarization, can also be improved. For this reason, in this report, we propose to enhance the capability of neural networks in the context of paraphrase detection through the use of traditional Information Retrieval (IR) techniques as input features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Objectives </h3>\n",
    "\n",
    "The main objective of this report is to evaluate the performance of a neural network model given different IR features. Additionally, it will take a look at how the number of features and hidden layers improve the overall performance of the model. These results will be compared among two different training sets that have been annotated for paraphrase detection. Below is the proposed architecture for our particular neural network: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Datasets </h3>\n",
    "\n",
    "We will be working with the Quora Question Pairs and Microsoft Research Paraphrase Corpus datasets for this project. You can find them in this folder labelled as 'msr_train.csv' and 'questions_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure to import all these modules\n",
    "import pandas as pd \n",
    "from pyemd import emd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at the Quora Question Pairs dataset\n",
    "quora_data = pd.read_csv(\"questions_train.csv\")\n",
    "quora_data.Sentence_1 = quora_data.Sentence_1.astype(str)\n",
    "quora_data.Sentence_2 = quora_data.Sentence_2.astype(str)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a look at the Microsoft Research Paraphrase dataset \n",
    "mrp_data = pd.read_csv(\"msr_train.csv\")\n",
    "mrp_data.Sentence_1 = mrp_data.Sentence_1.astype(str)\n",
    "mrp_data.Sentence_2 = mrp_data.Sentence_2.astype(str)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Preprocessing </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(sentence):\n",
    "    stop_words = stopwords.words('english')\n",
    "    processed_sentence = [word for word in sentence if not word in stop_words]\n",
    "    return processed_sentence \n",
    "def tokenize(sentence):\n",
    "    tokenized_sentence = sentence.lower().split()\n",
    "    return tokenized_sentence\n",
    "def lemmatize(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "    return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Engineering</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Word Mover's Distance </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain WMD here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_movers_distance(row):\n",
    "    sentence_one_tokenize = tokenize(row['Sentence_1'])\n",
    "    sentence_two_tokenize = tokenize(row['Sentence_2'])\n",
    "    filtered_sentence_one = remove_stop_words(sentence_one_tokenize)\n",
    "    filtered_sentence_two = remove_stop_words(sentence_two_tokenize)\n",
    "    distance = word_vectors.wmdistance(filtered_sentence_one, filtered_sentence_two)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Word Mover's Distance to Quora sentence pairs \n",
    "quora_data['WMD_distance'] = quora_data.apply(word_movers_distance, axis=1)\n",
    "quora_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Word Mover's Distance to MRP Corpus sentence pairs \n",
    "mrp_data['WMD_distance'] = mrp_data.apply(word_movers_distance, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Pairwise Cosine Similarity </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain Cosine Similarity here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(row):\n",
    "    sentence_one_tokenize = tokenize(row['Sentence_1'])\n",
    "    sentence_two_tokenize = tokenize(row['Sentence_2'])\n",
    "    filtered_sentence_one = remove_stop_words(sentence_one_tokenize)\n",
    "    filtered_sentence_two = remove_stop_words(sentence_two_tokenize)\n",
    "    #lemmatize to get the root words \n",
    "    lemmatize_sentence_one = lemmatize(filtered_sentence_one)\n",
    "    lemmatize_sentence_two = lemmatize(filtered_sentence_two)\n",
    "    tfidf = TfidfVectorizer(preprocessor=' '.join)\n",
    "    tfidf_matrix = tfidf.fit_transform([lemmatize_sentence_one, lemmatize_sentence_two])\n",
    "    similarity = cosine_similarity(tfidf_matrix)\n",
    "    return similarity[0,1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Cosine Similarity to MRP Corpus sentence pairs \n",
    "mrp_data['Cosine_Similarity'] = mrp_data.apply(calculate_cosine_similarity, axis=1)\n",
    "mrp_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Train Set & Test Set </h3>\n",
    "\n",
    "For training with less bias, we want to maintain a reasonably equal class distribution. We want to make sure that we have a balanced class of non-paraphrase, as well as paraphrase pairs of sentences. If this is not possible, as with most real-life scenarios, we need to think of a way to adjust our metric for evaluation in order to accomodate for this imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class distribution for MRP Corpus: \\n{}\".format(mrp_data['is_Paraphrase'].value_counts()))\n",
    "print(\"Class distribution for Quora Corpus: \\n{}\".format(quora_data['is_Paraphrase'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Model </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Results & Evaluation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> References </h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
